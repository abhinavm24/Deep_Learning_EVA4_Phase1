Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)
cuda
Inside ResNet Class Making conv1
Resnet self.conv1: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
Inside ResNet Class Making Batchnorm1
Inside ResNet Class Making Layer 1
Resnet self.layer1: Sequential(
  (0): BasicBlock(
    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
  (1): BasicBlock(
    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Inside ResNet Class Making Layer 2
Resnet self.layer2: Sequential(
  (0): BasicBlock(
    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): BasicBlock(
    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Inside ResNet Class Making Layer 3
Resnet self.layer3: Sequential(
  (0): BasicBlock(
    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): BasicBlock(
    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Inside ResNet Class Making Layer 4
Resnet self.layer4: Sequential(
  (0): BasicBlock(
    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential(
      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (1): BasicBlock(
    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (shortcut): Sequential()
  )
)
Inside ResNet Class Making GAP
Resnet self.Gap1: AdaptiveAvgPool2d(output_size=(1, 1))
Inside ResNet Class Making FC Layer
Resnet self.fc: Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 64, 32, 32]           1,728 |  Initial Convolution
       BatchNorm2d-2           [-1, 64, 32, 32]             128 | 
	   ----------------------------------------------------------
            Conv2d-3           [-1, 64, 32, 32]          36,864 |
       BatchNorm2d-4           [-1, 64, 32, 32]             128 |  Layer 1, Block 1 (3x3x64/1)
            Conv2d-5           [-1, 64, 32, 32]          36,864 |
       BatchNorm2d-6           [-1, 64, 32, 32]             128 | 
        BasicBlock-7           [-1, 64, 32, 32]               0
            Conv2d-8           [-1, 64, 32, 32]          36,864 |
       BatchNorm2d-9           [-1, 64, 32, 32]             128 |  Layer 1, Block 2 (3x3x64/1)
           Conv2d-10           [-1, 64, 32, 32]          36,864 |
      BatchNorm2d-11           [-1, 64, 32, 32]             128 |
       BasicBlock-12           [-1, 64, 32, 32]               0 
           Conv2d-13          [-1, 128, 16, 16]          73,728 | Skip Connection 1x1 stride 2 ->BN connecting to 128 layer, Also reduces size 32-> 16 
      BatchNorm2d-14          [-1, 128, 16, 16]             256 | thus enabling addition with Layer 2
	  -----------------------------------------------------------
           Conv2d-15          [-1, 128, 16, 16]         147,456 | 3x3 stride 2 that enables 64->128 channels & size reduction 32 -> 16
      BatchNorm2d-16          [-1, 128, 16, 16]             256 |
           Conv2d-17          [-1, 128, 16, 16]           8,192 | Layer 2, Block 1 (3x3x128/1)
      BatchNorm2d-18          [-1, 128, 16, 16]             256 |
       BasicBlock-19          [-1, 128, 16, 16]               0
           Conv2d-20          [-1, 128, 16, 16]         147,456 |
      BatchNorm2d-21          [-1, 128, 16, 16]             256 | Layer 2, Block 2 (3x3x128/1)
           Conv2d-22          [-1, 128, 16, 16]         147,456 |
      BatchNorm2d-23          [-1, 128, 16, 16]             256 |
       BasicBlock-24          [-1, 128, 16, 16]               0 |
           Conv2d-25            [-1, 256, 8, 8]         294,912 | Skip Connection 1x1 stride 2 ->BN connecting to 256 layer, Also reduces size 16-> 8
      BatchNorm2d-26            [-1, 256, 8, 8]             512 | thus enabling addition with Layer 3
	  -----------------------------------------------------------
           Conv2d-27            [-1, 256, 8, 8]         589,824 | 3x3 stride 2 that enables 128->256 channels & size reduction 16 -> 8
      BatchNorm2d-28            [-1, 256, 8, 8]             512 | 
           Conv2d-29            [-1, 256, 8, 8]          32,768 | Layer 3, Block 1 (3x3x256/1)
      BatchNorm2d-30            [-1, 256, 8, 8]             512 | 
       BasicBlock-31            [-1, 256, 8, 8]               0
           Conv2d-32            [-1, 256, 8, 8]         589,824 |
      BatchNorm2d-33            [-1, 256, 8, 8]             512 | Layer 3, Block 2 (3x3x256/1)
           Conv2d-34            [-1, 256, 8, 8]         589,824 |
      BatchNorm2d-35            [-1, 256, 8, 8]             512 |
       BasicBlock-36            [-1, 256, 8, 8]               0 |
           Conv2d-37            [-1, 512, 4, 4]       1,179,648 | Skip Connection 1x1 stride 2 ->BN connecting to 512 layer, Also reduces size 8-> 4
      BatchNorm2d-38            [-1, 512, 4, 4]           1,024 | thus enabling addition with Layer 4
	  -----------------------------------------------------------
           Conv2d-39            [-1, 512, 4, 4]       2,359,296 | 3x3 stride 2 that enables 256->512 channels & size reduction 8 -> 4
      BatchNorm2d-40            [-1, 512, 4, 4]           1,024 |
           Conv2d-41            [-1, 512, 4, 4]         131,072 | Layer 4, Block 1 (3x3x512/1)
      BatchNorm2d-42            [-1, 512, 4, 4]           1,024 | 
       BasicBlock-43            [-1, 512, 4, 4]               0
           Conv2d-44            [-1, 512, 4, 4]       2,359,296 |
      BatchNorm2d-45            [-1, 512, 4, 4]           1,024 | Layer 4, Block 2 (3x3x512/1)
           Conv2d-46            [-1, 512, 4, 4]       2,359,296 |
      BatchNorm2d-47            [-1, 512, 4, 4]           1,024 | 
       BasicBlock-48            [-1, 512, 4, 4]               0 |
	 ------------------------------------------------------------  
AdaptiveAvgPool2d-49            [-1, 512, 1, 1]               0 | GAP to reduce 512x4x4 To 512x1x1
     ------------------------------------------------------------
           Conv2d-50             [-1, 10, 1, 1]           5,120 | GAP to connect to Fully Connected Layer from 512x1x1 to 10x1x1
================================================================
Total params: 11,173,952
Trainable params: 11,173,952
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 11.25
Params size (MB): 42.63
Estimated Total Size (MB): 53.89
---
